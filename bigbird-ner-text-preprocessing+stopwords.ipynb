{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6901870f",
   "metadata": {},
   "source": [
    "## **BigBird NER Baseline in PyTorch with  CV Score 0.740**\n",
    "\n",
    "https://www.kaggle.com/competitions/feedback-prize-2021/overview\n",
    "\n",
    "- This notebook serves as an introductory guide for Kaggle's \"Feedback Prize - Evaluating Student Writing\" Competition using PyTorch. It outlines the process of training, inferring, and submitting a model to Kaggle with no internet connection. The current implementation features:\n",
    "\n",
    "* BigBird as the backbone (utilizing HuggingFace's TokenClassification head)\n",
    "* NER (Named Entity Recognition) approach (tokenizing with is_split_into_words=True)\n",
    "* Single fold\n",
    "* BigBird serves as the backbone for the Named Entity Recognition (NER) model. BigBird is a state-of-the-art transformer architecture designed to handle long sequences of input tokens effectively. It can manage token inputs as wide as 4096, making it particularly suitable for tasks involving large-scale text processing.\n",
    "\n",
    "- Modifying just a few lines of code allows for the evaluation of different PyTorch backbones and other experiments. When using a backbone that cannot handle 1024-wide tokens (unlike BigBird or LongFormer), a sliding window can be implemented during training and inference. BigBird, a state-of-the-art transformer, is capable of accepting large token inputs as wide as 4096. The arXiv paper can be found here.\n",
    "\n",
    "- This model employs HuggingFace's AutoModelForTokenClassification. To use a custom head, AutoModel can be used to build one separately. An example can be found in this TensorFlow notebook.\n",
    "\n",
    "- The tokenization process in this notebook uses tokenizer(txt.split(), is_split_into_words=True), which omits characters like \\n. To enable the model to recognize new paragraphs, the code needs to be rewritten without using is_split_into_words=True. An example is available in this TensorFlow notebook.\n",
    "\n",
    "- Many code snippets in this notebook come from Raghavendrakotala's excellent notebook, which can be found here. Don't forget to upvote Raghavendrakotala's notebook!\n",
    "\n",
    "* Configuration Options\n",
    "- This notebook can train a new model or load a pre-trained one (from a previous notebook version). Additionally, it can create new NER labels or load existing ones (from a previous notebook version). In this version, we will load both the model and NER labels.\n",
    "\n",
    "- This notebook can also load HuggingFace components (like tokenizers) from a Kaggle dataset or download them from the internet. After downloading from the internet, the components can be placed in a Kaggle dataset, allowing for offline access in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab1d262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:56:32.298660Z",
     "iopub.status.busy": "2021-12-24T18:56:32.297275Z",
     "iopub.status.idle": "2021-12-24T18:56:32.302646Z",
     "shell.execute_reply": "2021-12-24T18:56:32.303081Z",
     "shell.execute_reply.started": "2021-12-24T18:49:57.671659Z"
    },
    "papermill": {
     "duration": 0.039536,
     "end_time": "2021-12-24T18:56:32.303289",
     "exception": false,
     "start_time": "2021-12-24T18:56:32.263753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# DECLARE HOW MANY GPUS YOU WISH TO USE. \n",
    "# KAGGLE ONLY HAS 1, BUT OFFLINE, YOU CAN USE MORE\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #0,1,2,3 for four gpu\n",
    "\n",
    "# VERSION FOR SAVING MODEL WEIGHTS\n",
    "VER=26\n",
    "\n",
    "# IF VARIABLE IS NONE, THEN NOTEBOOK COMPUTES TOKENS\n",
    "# OTHERWISE NOTEBOOK LOADS TOKENS FROM PATH\n",
    "LOAD_TOKENS_FROM = './input/py-bigbird-v26'\n",
    "\n",
    "# IF VARIABLE IS NONE, THEN NOTEBOOK TRAINS A NEW MODEL\n",
    "# OTHERWISE IT LOADS YOUR PREVIOUSLY TRAINED MODEL\n",
    "LOAD_MODEL_FROM = None #'./input/py-bigbird-v26'\n",
    "\n",
    "# IF FOLLOWING IS NONE, THEN NOTEBOOK \n",
    "# USES INTERNET AND DOWNLOADS HUGGINGFACE \n",
    "# CONFIG, TOKENIZER, AND MODEL\n",
    "DOWNLOADED_MODEL_PATH = None #'./input/py-bigbird-v26' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4bc9d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOADED_MODEL_PATH is None:\n",
    "    DOWNLOADED_MODEL_PATH = 'model'    \n",
    "MODEL_NAME = 'google/bigbird-roberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30050c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:56:32.349529Z",
     "iopub.status.busy": "2021-12-24T18:56:32.349000Z",
     "iopub.status.idle": "2021-12-24T18:56:34.096290Z",
     "shell.execute_reply": "2021-12-24T18:56:34.096934Z",
     "shell.execute_reply.started": "2021-12-24T18:49:57.702899Z"
    },
    "papermill": {
     "duration": 1.773177,
     "end_time": "2021-12-24T18:56:34.097096",
     "exception": false,
     "start_time": "2021-12-24T18:56:32.323919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "config = {'model_name': MODEL_NAME,   \n",
    "         'max_length': 1024,\n",
    "         'train_batch_size':16,\n",
    "         'valid_batch_size':16,\n",
    "         'epochs':5,\n",
    "         'learning_rates': [2.5e-5, 2.5e-5, 2.5e-6, 2.5e-6, 2.5e-7],\n",
    "         'max_grad_norm':10,\n",
    "         'device': 'cuda' if cuda.is_available() else 'cpu'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f023f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS WILL COMPUTE VAL SCORE DURING COMMIT BUT NOT DURING SUBMIT\n",
    "COMPUTE_VAL_SCORE = True\n",
    "if len( os.listdir('./input/feedback-prize-2021/test') )>5:\n",
    "      COMPUTE_VAL_SCORE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7faa77",
   "metadata": {
    "papermill": {
     "duration": 0.040966,
     "end_time": "2021-12-24T18:56:34.171732",
     "exception": false,
     "start_time": "2021-12-24T18:56:34.130766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# How To Submit PyTorch Without Internet\n",
    "Many people ask me, how do I submit PyTorch models without internet? With HuggingFace Transformer, it's easy. Just download the following 3 things (1) model weights, (2) tokenizer files, (3) config file, and upload them to a Kaggle dataset. Below shows code how to get the files from HuggingFace for Google's BigBird-base. But this same code can download any transformer, like for example roberta-base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1556cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feb6ccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc0b348f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:56:34.249996Z",
     "iopub.status.busy": "2021-12-24T18:56:34.249225Z",
     "iopub.status.idle": "2021-12-24T18:56:43.169972Z",
     "shell.execute_reply": "2021-12-24T18:56:43.169471Z",
     "shell.execute_reply.started": "2021-12-24T18:49:59.132269Z"
    },
    "papermill": {
     "duration": 8.963092,
     "end_time": "2021-12-24T18:56:43.170108",
     "exception": false,
     "start_time": "2021-12-24T18:56:34.207016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/orangel/.cache/huggingface/hub/models--google--bigbird-roberta-base/snapshots/5a145f7852cba9bd431386a58137bf8a29903b90/config.json\n",
      "Model config BigBirdConfig {\n",
      "  \"_name_or_path\": \"google/bigbird-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"BigBirdForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_type\": \"block_sparse\",\n",
      "  \"block_size\": 64,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu_new\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"big_bird\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_random_blocks\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"rescale_embeddings\": false,\n",
      "  \"sep_token_id\": 66,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bias\": true,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50358\n",
      "}\n",
      "\n",
      "loading file spiece.model from cache at /home/orangel/.cache/huggingface/hub/models--google--bigbird-roberta-base/snapshots/5a145f7852cba9bd431386a58137bf8a29903b90/spiece.model\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/orangel/.cache/huggingface/hub/models--google--bigbird-roberta-base/snapshots/5a145f7852cba9bd431386a58137bf8a29903b90/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/orangel/.cache/huggingface/hub/models--google--bigbird-roberta-base/snapshots/5a145f7852cba9bd431386a58137bf8a29903b90/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/orangel/.cache/huggingface/hub/models--google--bigbird-roberta-base/snapshots/5a145f7852cba9bd431386a58137bf8a29903b90/config.json\n",
      "Model config BigBirdConfig {\n",
      "  \"_name_or_path\": \"google/bigbird-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"BigBirdForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_type\": \"block_sparse\",\n",
      "  \"block_size\": 64,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu_new\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"big_bird\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_random_blocks\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"rescale_embeddings\": false,\n",
      "  \"sep_token_id\": 66,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bias\": true,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50358\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/orangel/.cache/huggingface/hub/models--google--bigbird-roberta-base/snapshots/5a145f7852cba9bd431386a58137bf8a29903b90/config.json\n",
      "Model config BigBirdConfig {\n",
      "  \"_name_or_path\": \"google/bigbird-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"BigBirdForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_type\": \"block_sparse\",\n",
      "  \"block_size\": 64,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu_new\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"big_bird\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_random_blocks\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"rescale_embeddings\": false,\n",
      "  \"sep_token_id\": 66,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bias\": true,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50358\n",
      "}\n",
      "\n",
      "tokenizer config file saved in model/tokenizer_config.json\n",
      "Special tokens file saved in model/special_tokens_map.json\n",
      "loading configuration file config.json from cache at /home/orangel/.cache/huggingface/hub/models--google--bigbird-roberta-base/snapshots/5a145f7852cba9bd431386a58137bf8a29903b90/config.json\n",
      "Model config BigBirdConfig {\n",
      "  \"_name_or_path\": \"google/bigbird-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"BigBirdForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_type\": \"block_sparse\",\n",
      "  \"block_size\": 64,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu_new\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"big_bird\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_random_blocks\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"rescale_embeddings\": false,\n",
      "  \"sep_token_id\": 66,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bias\": true,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50358\n",
      "}\n",
      "\n",
      "Configuration saved in model/config.json\n",
      "loading weights file pytorch_model.bin from cache at /home/orangel/.cache/huggingface/hub/models--google--bigbird-roberta-base/snapshots/5a145f7852cba9bd431386a58137bf8a29903b90/pytorch_model.bin\n",
      "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BigBirdForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BigBirdForTokenClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Configuration saved in model/config.json\n",
      "Model weights saved in model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if DOWNLOADED_MODEL_PATH == 'model':\n",
    "#     os.mkdir('model')\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, add_prefix_space=True)\n",
    "    tokenizer.save_pretrained('model')\n",
    "\n",
    "    config_model = AutoConfig.from_pretrained(MODEL_NAME) \n",
    "    config_model.num_labels = 15\n",
    "    config_model.save_pretrained('model')\n",
    "\n",
    "    backbone = AutoModelForTokenClassification.from_pretrained(MODEL_NAME, config=config_model)\n",
    "    backbone.save_pretrained('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045f3e0b",
   "metadata": {
    "papermill": {
     "duration": 0.020416,
     "end_time": "2021-12-24T18:56:43.211378",
     "exception": false,
     "start_time": "2021-12-24T18:56:43.190962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data and Libraries\n",
    "In addition to loading the train dataframe, we will load all the train and text files and save them in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0843547",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-24T18:56:43.258134Z",
     "iopub.status.busy": "2021-12-24T18:56:43.257382Z",
     "iopub.status.idle": "2021-12-24T18:56:43.259346Z",
     "shell.execute_reply": "2021-12-24T18:56:43.259745Z",
     "shell.execute_reply.started": "2021-12-24T18:50:08.438077Z"
    },
    "papermill": {
     "duration": 0.027699,
     "end_time": "2021-12-24T18:56:43.259877",
     "exception": false,
     "start_time": "2021-12-24T18:56:43.232178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np, os \n",
    "import pandas as pd, gc \n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "279c43f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:56:43.308509Z",
     "iopub.status.busy": "2021-12-24T18:56:43.308011Z",
     "iopub.status.idle": "2021-12-24T18:56:45.144095Z",
     "shell.execute_reply": "2021-12-24T18:56:45.143617Z",
     "shell.execute_reply.started": "2021-12-24T18:50:08.446201Z"
    },
    "papermill": {
     "duration": 1.863642,
     "end_time": "2021-12-24T18:56:45.144220",
     "exception": false,
     "start_time": "2021-12-24T18:56:43.280578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144293, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./input/feedback-prize-2021/train.csv')\n",
    "print( train_df.shape )\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43812c3a",
   "metadata": {},
   "source": [
    "This code reads in text files located in the directory './input/feedback-prize-2021/test', and creates a list of file names and a corresponding list of the text content in those files. It then creates a pandas DataFrame object with two columns: 'id' and 'text', where 'id' corresponds to the file names and 'text' corresponds to the text content in those files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "065d2ef8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:56:45.193325Z",
     "iopub.status.busy": "2021-12-24T18:56:45.192814Z",
     "iopub.status.idle": "2021-12-24T18:56:45.229337Z",
     "shell.execute_reply": "2021-12-24T18:56:45.230033Z",
     "shell.execute_reply.started": "2021-12-24T18:50:10.573663Z"
    },
    "papermill": {
     "duration": 0.063091,
     "end_time": "2021-12-24T18:56:45.230167",
     "exception": false,
     "start_time": "2021-12-24T18:56:45.167076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>During a group project, have you ever asked a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DF920E0A7337</td>\n",
       "      <td>Have you ever asked more than one person for h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18409261F5C2</td>\n",
       "      <td>80% of Americans believe seeking multiple opin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D46BCB48440A</td>\n",
       "      <td>When people ask for advice,they sometimes talk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  0FB0700DAF44  During a group project, have you ever asked a ...\n",
       "1  D72CB1C11673  Making choices in life can be very difficult. ...\n",
       "2  DF920E0A7337  Have you ever asked more than one person for h...\n",
       "3  18409261F5C2  80% of Americans believe seeking multiple opin...\n",
       "4  D46BCB48440A  When people ask for advice,they sometimes talk..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\n",
    "test_names, test_texts = [], []\n",
    "\n",
    "for f in list(os.listdir('./input/feedback-prize-2021/test')):\n",
    "    test_names.append(f.replace('.txt', ''))\n",
    "    test_texts.append(open('./input/feedback-prize-2021/test/' + f, 'r').read())\n",
    "    \n",
    "test_texts = pd.DataFrame({'id': test_names, 'text': test_texts})\n",
    "test_texts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440d8bb3",
   "metadata": {},
   "source": [
    "############# -------------------- ###################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e08ace",
   "metadata": {},
   "source": [
    "#### Using string.punctuation and string.digits constants: \n",
    "- You can use the string.punctuation constant to get all punctuation characters, \n",
    "- and the string.digits constant to get all digits. \n",
    "- Then, you can remove these characters from the string using the str.translate() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abe95821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "translator = str.maketrans('', '', string.punctuation + string.digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1639844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>During a group project have you ever asked a g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Making choices in life can be very difficult P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DF920E0A7337</td>\n",
       "      <td>Have you ever asked more than one person for h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18409261F5C2</td>\n",
       "      <td>of Americans believe seeking multiple opinion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D46BCB48440A</td>\n",
       "      <td>When people ask for advicethey sometimes talk ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  0FB0700DAF44  During a group project have you ever asked a g...\n",
       "1  D72CB1C11673  Making choices in life can be very difficult P...\n",
       "2  DF920E0A7337  Have you ever asked more than one person for h...\n",
       "3  18409261F5C2   of Americans believe seeking multiple opinion...\n",
       "4  D46BCB48440A  When people ask for advicethey sometimes talk ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the translation table to the \"text\" column to remove punctuations and digits\n",
    "test_texts[\"text\"] = test_texts[\"text\"].apply(lambda x: x.translate(translator))\n",
    "test_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff4608f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:56:45.279209Z",
     "iopub.status.busy": "2021-12-24T18:56:45.278657Z",
     "iopub.status.idle": "2021-12-24T18:57:44.248490Z",
     "shell.execute_reply": "2021-12-24T18:57:44.248961Z",
     "shell.execute_reply.started": "2021-12-24T18:50:10.616344Z"
    },
    "papermill": {
     "duration": 58.996899,
     "end_time": "2021-12-24T18:57:44.249132",
     "exception": false,
     "start_time": "2021-12-24T18:56:45.252233",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 15594/15594 [00:00<00:00, 140490.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90F900708083</td>\n",
       "      <td>Dear Principal,\\n\\nI heard about the two new c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29BE597866EE</td>\n",
       "      <td>Dear Principal of SCHOOL_NAME,\\n\\nCommunity se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3B783778AA40</td>\n",
       "      <td>Venus is a planet that for a fact humans could...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B5330C56B5B8</td>\n",
       "      <td>I think that Lukes point of viewIf you were go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0C7779B7276</td>\n",
       "      <td>Dear Ms. Principal,\\n\\nCommunity Service is ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  90F900708083  Dear Principal,\\n\\nI heard about the two new c...\n",
       "1  29BE597866EE  Dear Principal of SCHOOL_NAME,\\n\\nCommunity se...\n",
       "2  3B783778AA40  Venus is a planet that for a fact humans could...\n",
       "3  B5330C56B5B8  I think that Lukes point of viewIf you were go...\n",
       "4  B0C7779B7276  Dear Ms. Principal,\\n\\nCommunity Service is ex..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\n",
    "test_names, train_texts = [], [] # Initialize two empty lists, test_names and train_texts.\n",
    "\n",
    "# Iterate through the list of files in the ./input/feedback-prize-2021/train directory using a for loop \n",
    "# with a progress bar from tqdm.\n",
    "\n",
    "# For each file, append the file name without the '.txt' extension to the test_names list\n",
    "for f in tqdm(list(os.listdir('./input/feedback-prize-2021/train'))):\n",
    "    test_names.append(f.replace('.txt', ''))\n",
    "    # Read the content of each file and append it to the train_texts list.\n",
    "    train_texts.append(open('./input/feedback-prize-2021/train/' + f, 'r').read())\n",
    "\n",
    "# Create a pandas DataFrame called train_text_df with two columns: \n",
    "# 'id' (file names) and 'text' (file contents).    \n",
    "train_text_df = pd.DataFrame({'id': test_names, 'text': train_texts})\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "727009a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ed6934e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90F900708083</td>\n",
       "      <td>dear principal\\n\\ni heard about the two new ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29BE597866EE</td>\n",
       "      <td>dear principal of schoolname\\n\\ncommunity serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3B783778AA40</td>\n",
       "      <td>venus is a planet that for a fact humans could...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B5330C56B5B8</td>\n",
       "      <td>i think that lukes point of viewif you were go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0C7779B7276</td>\n",
       "      <td>dear ms principal\\n\\ncommunity service is exac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  90F900708083  dear principal\\n\\ni heard about the two new ce...\n",
       "1  29BE597866EE  dear principal of schoolname\\n\\ncommunity serv...\n",
       "2  3B783778AA40  venus is a planet that for a fact humans could...\n",
       "3  B5330C56B5B8  i think that lukes point of viewif you were go...\n",
       "4  B0C7779B7276  dear ms principal\\n\\ncommunity service is exac..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_df[\"text\"] = train_text_df[\"text\"].str.lower()\n",
    "\n",
    "# apply the translation table to the \"text\" column to remove punctuations and digits\n",
    "train_text_df[\"text\"] = train_text_df[\"text\"].apply(lambda x: x.translate(translator))\n",
    "\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cae4758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/orangel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/orangel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed92462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Load English stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54ba1f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Filter out stopwords\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # Reconstruct the text\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "054007aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90F900708083</td>\n",
       "      <td>dear principal heard two new cell phone polici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29BE597866EE</td>\n",
       "      <td>dear principal schoolname community service re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3B783778AA40</td>\n",
       "      <td>venus planet fact humans could live gases atmo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B5330C56B5B8</td>\n",
       "      <td>think lukes point viewif going ask someone wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0C7779B7276</td>\n",
       "      <td>dear ms principal community service exactly so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  90F900708083  dear principal heard two new cell phone polici...\n",
       "1  29BE597866EE  dear principal schoolname community service re...\n",
       "2  3B783778AA40  venus planet fact humans could live gases atmo...\n",
       "3  B5330C56B5B8  think lukes point viewif going ask someone wou...\n",
       "4  B0C7779B7276  dear ms principal community service exactly so..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts\n",
    "# Apply the remove_stopwords function to the 'text' column from train_text_df\n",
    "train_text_df['text'] = train_text_df['text'].apply(remove_stopwords)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "754a36a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90F900708083</td>\n",
       "      <td>dear principal heard two new cell phone polici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29BE597866EE</td>\n",
       "      <td>dear principal schoolname community service re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3B783778AA40</td>\n",
       "      <td>venus planet fact humans could live gases atmo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B5330C56B5B8</td>\n",
       "      <td>think lukes point viewif going ask someone wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0C7779B7276</td>\n",
       "      <td>dear ms principal community service exactly so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  90F900708083  dear principal heard two new cell phone polici...\n",
       "1  29BE597866EE  dear principal schoolname community service re...\n",
       "2  3B783778AA40  venus planet fact humans could live gases atmo...\n",
       "3  B5330C56B5B8  think lukes point viewif going ask someone wou...\n",
       "4  B0C7779B7276  dear ms principal community service exactly so..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the remove_stopwords function to the 'text' column\n",
    "train_text_df['text'] = train_text_df['text'].apply(remove_stopwords)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6b16f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90F900708083</td>\n",
       "      <td>dear principal heard two new cell phone polici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29BE597866EE</td>\n",
       "      <td>dear principal schoolname community service re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3B783778AA40</td>\n",
       "      <td>venus planet fact humans could live gases atmo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B5330C56B5B8</td>\n",
       "      <td>think lukes point viewif going ask someone wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0C7779B7276</td>\n",
       "      <td>dear ms principal community service exactly so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  90F900708083  dear principal heard two new cell phone polici...\n",
       "1  29BE597866EE  dear principal schoolname community service re...\n",
       "2  3B783778AA40  venus planet fact humans could live gases atmo...\n",
       "3  B5330C56B5B8  think lukes point viewif going ask someone wou...\n",
       "4  B0C7779B7276  dear ms principal community service exactly so..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_df['text'] = train_text_df['text'].str.replace('\\n\\n', ' ')\n",
    "\n",
    "# Display the updated DataFrame\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dde9af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587592e7",
   "metadata": {
    "papermill": {
     "duration": 0.168711,
     "end_time": "2021-12-24T18:57:44.586488",
     "exception": false,
     "start_time": "2021-12-24T18:57:44.417777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Convert Train Text to NER Labels\n",
    "We will now convert all text words into NER labels and save in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60da4700",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:57:44.930413Z",
     "iopub.status.busy": "2021-12-24T18:57:44.929846Z",
     "iopub.status.idle": "2021-12-24T18:57:58.922864Z",
     "shell.execute_reply": "2021-12-24T18:57:58.923311Z",
     "shell.execute_reply.started": "2021-12-24T18:50:55.987903Z"
    },
    "papermill": {
     "duration": 14.170019,
     "end_time": "2021-12-24T18:57:58.923453",
     "exception": false,
     "start_time": "2021-12-24T18:57:44.753434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15594, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E1FA876D6E6C</td>\n",
       "      <td>Dear Senator,\\n\\nI am writting this letter to ...</td>\n",
       "      <td>[O, O, B-Lead, I-Lead, I-Lead, I-Lead, I-Lead,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8AC1D6E165CD</td>\n",
       "      <td>Dear Principal, I believe in policy 2. Kids ar...</td>\n",
       "      <td>[O, O, B-Position, I-Position, I-Position, I-P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45EF6A4EDB1A</td>\n",
       "      <td>Summer projects are no fun, but they are a gre...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0070361406D</td>\n",
       "      <td>The author who wrote \"The challenge of Explori...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>839F4F7F7DD7</td>\n",
       "      <td>Our school systems have seen many changes as t...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  E1FA876D6E6C  Dear Senator,\\n\\nI am writting this letter to ...   \n",
       "1  8AC1D6E165CD  Dear Principal, I believe in policy 2. Kids ar...   \n",
       "2  45EF6A4EDB1A  Summer projects are no fun, but they are a gre...   \n",
       "3  B0070361406D  The author who wrote \"The challenge of Explori...   \n",
       "4  839F4F7F7DD7  Our school systems have seen many changes as t...   \n",
       "\n",
       "                                            entities  \n",
       "0  [O, O, B-Lead, I-Lead, I-Lead, I-Lead, I-Lead,...  \n",
       "1  [O, O, B-Position, I-Position, I-Position, I-P...  \n",
       "2  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "3  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "4  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not LOAD_TOKENS_FROM:\n",
    "    all_entities = []\n",
    "    for ii,i in enumerate(train_text_df.iterrows()):\n",
    "        if ii%100==0: print(ii,', ',end='')\n",
    "        total = i[1]['text'].split().__len__()\n",
    "        entities = [\"O\"]*total\n",
    "        \n",
    "        for j in train_df[train_df['id'] == i[1]['id']].iterrows():\n",
    "            discourse = j[1]['discourse_type']\n",
    "            list_ix = [int(x) for x in j[1]['predictionstring'].split(' ')]\n",
    "            entities[list_ix[0]] = f\"B-{discourse}\"\n",
    "            \n",
    "            for k in list_ix[1:]: entities[k] = f\"I-{discourse}\"\n",
    "                \n",
    "        all_entities.append(entities)\n",
    "        \n",
    "    train_text_df['entities'] = all_entities\n",
    "    train_text_df.to_csv('train_NER.csv',index=False)\n",
    "    \n",
    "else:\n",
    "    from ast import literal_eval\n",
    "    train_text_df = pd.read_csv(f'{LOAD_TOKENS_FROM}/train_NER.csv')\n",
    "    # pandas saves lists as string, we must convert back\n",
    "    train_text_df.entities = train_text_df.entities.apply(lambda x: literal_eval(x) )\n",
    "    \n",
    "print( train_text_df.shape )\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdfa6c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:57:59.267678Z",
     "iopub.status.busy": "2021-12-24T18:57:59.266890Z",
     "iopub.status.idle": "2021-12-24T18:57:59.268632Z",
     "shell.execute_reply": "2021-12-24T18:57:59.269116Z",
     "shell.execute_reply.started": "2021-12-24T18:51:08.881395Z"
    },
    "papermill": {
     "duration": 0.176747,
     "end_time": "2021-12-24T18:57:59.269256",
     "exception": false,
     "start_time": "2021-12-24T18:57:59.092509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CREATE DICTIONARIES THAT WE CAN USE DURING TRAIN AND INFER\n",
    "output_labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n",
    "          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n",
    "\n",
    "labels_to_ids = {v:k for k,v in enumerate(output_labels)}\n",
    "ids_to_labels = {k:v for k,v in enumerate(output_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55712d87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:57:59.610556Z",
     "iopub.status.busy": "2021-12-24T18:57:59.609947Z",
     "iopub.status.idle": "2021-12-24T18:57:59.612514Z",
     "shell.execute_reply": "2021-12-24T18:57:59.612925Z",
     "shell.execute_reply.started": "2021-12-24T18:51:08.891029Z"
    },
    "papermill": {
     "duration": 0.176108,
     "end_time": "2021-12-24T18:57:59.613066",
     "exception": false,
     "start_time": "2021-12-24T18:57:59.436958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-Lead': 1,\n",
       " 'I-Lead': 2,\n",
       " 'B-Position': 3,\n",
       " 'I-Position': 4,\n",
       " 'B-Claim': 5,\n",
       " 'I-Claim': 6,\n",
       " 'B-Counterclaim': 7,\n",
       " 'I-Counterclaim': 8,\n",
       " 'B-Rebuttal': 9,\n",
       " 'I-Rebuttal': 10,\n",
       " 'B-Evidence': 11,\n",
       " 'I-Evidence': 12,\n",
       " 'B-Concluding Statement': 13,\n",
       " 'I-Concluding Statement': 14}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f804100f",
   "metadata": {
    "papermill": {
     "duration": 0.166097,
     "end_time": "2021-12-24T18:57:59.945482",
     "exception": false,
     "start_time": "2021-12-24T18:57:59.779385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define the dataset function\n",
    "Below is our PyTorch dataset function. It always outputs tokens and attention. During training it also provides labels. And during inference it also provides word ids to help convert token predictions into word predictions.\n",
    "\n",
    "Note that we use `text.split()` and `is_split_into_words=True` when we convert train text to labeled train tokens. This is how the HugglingFace tutorial does it. However, this removes characters like `\\n` new paragraph. If you want your model to see new paragraphs, then we need to map words to tokens ourselves using `return_offsets_mapping=True`. See my TensorFlow notebook [here][1] for an example.\n",
    "\n",
    "Some of the following code comes from the example at HuggingFace [here][2]. However I think the code at that link is wrong. The HuggingFace original code is [here][3]. With the flag `LABEL_ALL` we can either label just the first subword token (when one word has more than one subword token). Or we can label all the subword tokens (with the word's label). In this notebook version, we label all the tokens. There is a Kaggle discussion [here][4]\n",
    "\n",
    "[1]: https://www.kaggle.com/cdeotte/tensorflow-longformer-ner-cv-0-617\n",
    "[2]: https://huggingface.co/docs/transformers/custom_datasets#tok_ner\n",
    "[3]: https://github.com/huggingface/transformers/blob/86b40073e9aee6959c8c85fcba89e47b432c4f4d/examples/pytorch/token-classification/run_ner.py#L371\n",
    "[4]: https://www.kaggle.com/c/feedback-prize-2021/discussion/296713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d3eb2e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:58:00.293085Z",
     "iopub.status.busy": "2021-12-24T18:58:00.292201Z",
     "iopub.status.idle": "2021-12-24T18:58:00.294098Z",
     "shell.execute_reply": "2021-12-24T18:58:00.294599Z",
     "shell.execute_reply.started": "2021-12-24T18:51:08.900252Z"
    },
    "papermill": {
     "duration": 0.181569,
     "end_time": "2021-12-24T18:58:00.294728",
     "exception": false,
     "start_time": "2021-12-24T18:58:00.113159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABEL_ALL_SUBTOKENS = True\n",
    "\n",
    "class dataset(Dataset):\n",
    "  def __init__(self, dataframe, tokenizer, max_len, get_wids):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.get_wids = get_wids # for validation\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        # GET TEXT AND WORD LABELS \n",
    "        text = self.data.text[index]        \n",
    "        word_labels = self.data.entities[index] if not self.get_wids else None\n",
    "\n",
    "        # TOKENIZE TEXT\n",
    "        encoding = self.tokenizer(text.split(),\n",
    "                             is_split_into_words=True,\n",
    "                             #return_offsets_mapping=True, \n",
    "                             padding='max_length', \n",
    "                             truncation=True, \n",
    "                             max_length=self.max_len)\n",
    "        word_ids = encoding.word_ids()  \n",
    "        \n",
    "        # CREATE TARGETS\n",
    "        if not self.get_wids:\n",
    "            previous_word_idx = None\n",
    "            label_ids = []\n",
    "            for word_idx in word_ids:                            \n",
    "                if word_idx is None:\n",
    "                    label_ids.append(-100)\n",
    "                elif word_idx != previous_word_idx:              \n",
    "                    label_ids.append( labels_to_ids[word_labels[word_idx]] )\n",
    "                else:\n",
    "                    if LABEL_ALL_SUBTOKENS:\n",
    "                        label_ids.append( labels_to_ids[word_labels[word_idx]] )\n",
    "                    else:\n",
    "                        label_ids.append(-100)\n",
    "                previous_word_idx = word_idx\n",
    "            encoding['labels'] = label_ids\n",
    "\n",
    "        # CONVERT TO TORCH TENSORS\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        if self.get_wids: \n",
    "            word_ids2 = [w if w is not None else -1 for w in word_ids]\n",
    "            item['wids'] = torch.as_tensor(word_ids2)\n",
    "        \n",
    "        return item\n",
    "\n",
    "  def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599d4367",
   "metadata": {
    "papermill": {
     "duration": 0.166423,
     "end_time": "2021-12-24T18:58:00.631003",
     "exception": false,
     "start_time": "2021-12-24T18:58:00.464580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Train and Validation Dataloaders\n",
    "We will use the same train and validation subsets as my TensorFlow notebook [here][1]. Then we can compare results. And/or experiment with ensembling the validation fold predictions.\n",
    "\n",
    "[1]: https://www.kaggle.com/cdeotte/tensorflow-longformer-ner-cv-0-617"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e9e5dde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15594 train texts. We will split 90% 10% for validation.\n"
     ]
    }
   ],
   "source": [
    "# CHOOSE VALIDATION INDEXES (that match my TF notebook)\n",
    "IDS = train_df.id.unique()\n",
    "print('There are',len(IDS),'train texts. We will split 90% 10% for validation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "952d17f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:58:00.983177Z",
     "iopub.status.busy": "2021-12-24T18:58:00.982408Z",
     "iopub.status.idle": "2021-12-24T18:58:00.995552Z",
     "shell.execute_reply": "2021-12-24T18:58:00.995117Z",
     "shell.execute_reply.started": "2021-12-24T18:51:08.914209Z"
    },
    "papermill": {
     "duration": 0.19708,
     "end_time": "2021-12-24T18:58:00.995662",
     "exception": false,
     "start_time": "2021-12-24T18:58:00.798582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRAIN VALID SPLIT 90% 10%\n",
    "np.random.seed(42)\n",
    "# Sample 30% of the unique IDs\n",
    "# sampled_IDS = np.random.choice(IDS, int(0.3 * len(IDS)), replace=False)\n",
    "\n",
    "# Sample 100% of the unique IDs\n",
    "train_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\n",
    "valid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)\n",
    "np.random.seed(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b238015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (15594, 3)\n",
      "TRAIN Dataset: (14034, 2)\n",
      "TEST Dataset: (1560, 3)\n"
     ]
    }
   ],
   "source": [
    "# CREATE TRAIN SUBSET AND VALID SUBSET\n",
    "data = train_text_df[['id','text', 'entities']]\n",
    "train_dataset = data.loc[data['id'].isin(IDS[train_idx]),['text', 'entities']].reset_index(drop=True)\n",
    "test_dataset = data.loc[data['id'].isin(IDS[valid_idx])].reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e483c954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:58:01.375443Z",
     "iopub.status.busy": "2021-12-24T18:58:01.374581Z",
     "iopub.status.idle": "2021-12-24T18:58:01.581775Z",
     "shell.execute_reply": "2021-12-24T18:58:01.582736Z",
     "shell.execute_reply.started": "2021-12-24T18:51:08.948599Z"
    },
    "papermill": {
     "duration": 0.420181,
     "end_time": "2021-12-24T18:58:01.582956",
     "exception": false,
     "start_time": "2021-12-24T18:58:01.162775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spiece.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(DOWNLOADED_MODEL_PATH) \n",
    "training_set = dataset(train_dataset, tokenizer, config['max_length'], False)\n",
    "testing_set = dataset(test_dataset, tokenizer, config['max_length'], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d92b4fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:58:02.077974Z",
     "iopub.status.busy": "2021-12-24T18:58:02.077127Z",
     "iopub.status.idle": "2021-12-24T18:58:02.079685Z",
     "shell.execute_reply": "2021-12-24T18:58:02.079213Z",
     "shell.execute_reply.started": "2021-12-24T18:51:09.112378Z"
    },
    "papermill": {
     "duration": 0.213192,
     "end_time": "2021-12-24T18:58:02.079798",
     "exception": false,
     "start_time": "2021-12-24T18:58:01.866606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRAIN DATASET AND VALID DATASET\n",
    "train_params = {'batch_size': config['train_batch_size'],\n",
    "                'shuffle': True,\n",
    "                'num_workers': 8,\n",
    "                'pin_memory':True\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': config['valid_batch_size'],\n",
    "                'shuffle': False,\n",
    "                'num_workers':8,\n",
    "                'pin_memory':True\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "# TEST DATASET\n",
    "test_texts_set = dataset(test_texts, tokenizer, config['max_length'], True)\n",
    "test_texts_loader = DataLoader(test_texts_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f77f70a",
   "metadata": {
    "papermill": {
     "duration": 0.177586,
     "end_time": "2021-12-24T18:58:02.426035",
     "exception": false,
     "start_time": "2021-12-24T18:58:02.248449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train Model\n",
    "The PyTorch train function is taken from Raghavendrakotala's great notebook [here][1]. I assume it uses a masked loss which avoids computing loss when target is `-100`. If not, we need to update this.\n",
    "\n",
    "In Kaggle notebooks, we will train our model for 5 epochs `batch_size=4` with Adam optimizer and learning rates `LR = [2.5e-5, 2.5e-5, 2.5e-6, 2.5e-6, 2.5e-7]`. The loaded model was trained offline with `batch_size=8` and `LR = [5e-5, 5e-5, 5e-6, 5e-6, 5e-7]`. (Note the learning rate changes `e-5`, `e-6`, and `e-7`). Using `batch_size=4` will probably achieve a better validation score than `batch_size=8`, but I haven't tried yet.\n",
    "\n",
    "[1]: https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a68b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = config['epochs']\n",
    "unfreeze_epochs = [2, 3] # Epochs when we want to unfreeze additional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29abc90e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file model/config.json\n",
      "Model config BigBirdConfig {\n",
      "  \"_name_or_path\": \"model/config.json\",\n",
      "  \"architectures\": [\n",
      "    \"BigBirdForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_type\": \"block_sparse\",\n",
      "  \"block_size\": 64,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu_new\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"big_bird\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_random_blocks\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"rescale_embeddings\": false,\n",
      "  \"sep_token_id\": 66,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bias\": true,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50358\n",
      "}\n",
      "\n",
      "loading weights file model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BigBirdForTokenClassification.\n",
      "\n",
      "All the weights of BigBirdForTokenClassification were initialized from the model checkpoint at model/pytorch_model.bin.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BigBirdForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# CREATE MODEL\n",
    "config_model = AutoConfig.from_pretrained(DOWNLOADED_MODEL_PATH+'/config.json') \n",
    "model = AutoModelForTokenClassification.from_pretrained(DOWNLOADED_MODEL_PATH+'/pytorch_model.bin', config=config_model)\n",
    "\n",
    "model.to(config['device'])\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=config['learning_rates'][0])\n",
    "total_steps = len(training_loader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d61097b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:58:02.782857Z",
     "iopub.status.busy": "2021-12-24T18:58:02.781997Z",
     "iopub.status.idle": "2021-12-24T18:58:02.784536Z",
     "shell.execute_reply": "2021-12-24T18:58:02.784093Z",
     "shell.execute_reply.started": "2021-12-24T18:51:09.120299Z"
    },
    "papermill": {
     "duration": 0.18811,
     "end_time": "2021-12-24T18:58:02.784655",
     "exception": false,
     "start_time": "2021-12-24T18:58:02.596545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    #tr_preds, tr_labels = [], []\n",
    "    \n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['input_ids'].to(config['device'], dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(config['device'], dtype = torch.long)\n",
    "        labels = batch['labels'].to(config['device'], dtype = torch.long)\n",
    "\n",
    "        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict=False)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        if idx % 200==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss after {idx:04d} training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "        \n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        #tr_labels.extend(labels)\n",
    "        #tr_preds.extend(predictions)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=config['max_grad_norm']\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Prevent exploding gradients\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48a9977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_bert_layers(model, num_layers_to_unfreeze):\n",
    "    for layer in model.bert.encoder.layer[-num_layers_to_unfreeze:]:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0846d600",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:58:15.333655Z",
     "iopub.status.busy": "2021-12-24T18:58:15.333077Z",
     "iopub.status.idle": "2021-12-24T18:58:22.039962Z",
     "shell.execute_reply": "2021-12-24T18:58:22.039452Z",
     "shell.execute_reply.started": "2021-12-24T18:51:20.902537Z"
    },
    "papermill": {
     "duration": 6.881216,
     "end_time": "2021-12-24T18:58:22.040114",
     "exception": false,
     "start_time": "2021-12-24T18:58:15.158898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Training epoch: 1\n",
      "### LR = 2.5e-05\n",
      "\n",
      "Training loss after 0000 training steps: 2.6822750568389893\n",
      "Training loss after 0200 training steps: 1.1064895729520428\n",
      "Training loss after 0400 training steps: 0.9459145409507942\n",
      "Training loss after 0600 training steps: 0.8736576732502206\n",
      "Training loss after 0800 training steps: 0.8251651139295056\n",
      "Training loss epoch: 0.8100140699968251\n",
      "Training accuracy epoch: 0.7423063334921682\n",
      "### Training epoch: 2\n",
      "### LR = 2.5e-05\n",
      "\n",
      "Training loss after 0000 training steps: 0.4712039828300476\n",
      "Training loss after 0200 training steps: 0.6118609144616483\n",
      "Training loss after 0400 training steps: 0.5998665367130033\n",
      "Training loss after 0600 training steps: 0.6038803077378805\n",
      "Training loss after 0800 training steps: 0.6003204164433569\n",
      "Training loss epoch: 0.5983312263711439\n",
      "Training accuracy epoch: 0.7973084662773199\n",
      "### Training epoch: 3\n",
      "### LR = 2.5e-06\n",
      "\n",
      "Training loss after 0000 training steps: 0.6126350164413452\n",
      "Training loss after 0200 training steps: 0.516176141909699\n",
      "Training loss after 0400 training steps: 0.5159014141619057\n",
      "Training loss after 0600 training steps: 0.5169232592804857\n",
      "Training loss after 0800 training steps: 0.5163597761840558\n",
      "Training loss epoch: 0.5161435978491377\n",
      "Training accuracy epoch: 0.8213358177173818\n",
      "### Training epoch: 4\n",
      "### LR = 2.5e-06\n",
      "\n",
      "Training loss after 0000 training steps: 0.5369243025779724\n",
      "Training loss after 0200 training steps: 0.4548393052015732\n",
      "Training loss after 0400 training steps: 0.4560493742884543\n",
      "Training loss after 0600 training steps: 0.4541900204045205\n",
      "Training loss after 0800 training steps: 0.45357523979467995\n",
      "Training loss epoch: 0.45293582035631685\n",
      "Training accuracy epoch: 0.8413567223135606\n",
      "### Training epoch: 5\n",
      "### LR = 2.5e-07\n",
      "\n",
      "Training loss after 0000 training steps: 0.40747785568237305\n",
      "Training loss after 0200 training steps: 0.4170531228703646\n",
      "Training loss after 0400 training steps: 0.41216555876922134\n",
      "Training loss after 0600 training steps: 0.40960915493290756\n",
      "Training loss after 0800 training steps: 0.4090260738290651\n",
      "Training loss epoch: 0.4075942961393022\n",
      "Training accuracy epoch: 0.8563582250691884\n"
     ]
    }
   ],
   "source": [
    "# epoch 5\n",
    "# Training loss after 0400 training steps: 0.5081020672422395\n",
    "# LOOP TO TRAIN MODEL (or load model)\n",
    "if not LOAD_MODEL_FROM:\n",
    "    for epoch in range(config['epochs']):    \n",
    "        print(f\"### Training epoch: {epoch + 1}\")\n",
    "        \n",
    "        if epoch in unfreeze_epochs:\n",
    "            num_layers_to_unfreeze = 3 # Number of layers to unfreeze at each epoch\n",
    "            unfreeze_bert_layers(model, num_layers_to_unfreeze)\n",
    "        \n",
    "        for g in optimizer.param_groups: \n",
    "            g['lr'] = config['learning_rates'][epoch]\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        print(f'### LR = {lr}\\n')\n",
    "        \n",
    "        train(epoch)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    torch.save(model.state_dict(), f'bigbird_v{VER}.pt')\n",
    "else:\n",
    "    model.load_state_dict(torch.load(f'{LOAD_MODEL_FROM}/bigbird_v{VER}.pt'))\n",
    "    print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75845237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the model\n",
    "save_path = \"model_02_weights.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09c2026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "486b7b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BigBirdForTokenClassification(\n",
       "  (bert): BigBirdModel(\n",
       "    (embeddings): BigBirdEmbeddings(\n",
       "      (word_embeddings): Embedding(50358, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(4096, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BigBirdEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved state dictionary\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "\n",
    "# Set the model to evaluation mode (important for models with batch normalization, dropout, etc.)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c316cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37ddcbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUStatCollection(host=Anvil, [\n",
      "  \u001b[36m[0]\u001b[m \u001b[34mNVIDIA RTX A6000\u001b[m |\u001b[31m 44°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 1804\u001b[m / \u001b[33m49140\u001b[m MB |\n",
      "])\n"
     ]
    }
   ],
   "source": [
    "import gpustat\n",
    "\n",
    "# Get GPU stats\n",
    "gpu_stats = gpustat.GPUStatCollection.new_query()\n",
    "\n",
    "# Print formatted GPU stats\n",
    "print(gpu_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a92577",
   "metadata": {
    "papermill": {
     "duration": 0.172006,
     "end_time": "2021-12-24T18:58:22.383000",
     "exception": false,
     "start_time": "2021-12-24T18:58:22.210994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference and Validation Code\n",
    "We will infer in batches using our data loader which is faster than inferring one text at a time with a for-loop. The metric code is taken from Rob Mulla's great notebook [here][2]. Our model achieves validation F1 score 0.615! \n",
    "\n",
    "During inference our model will make predictions for each subword token. Some single words consist of multiple subword tokens. In the code below, we use a word's first subword token prediction as the label for the entire word. We can try other approaches, like averaging all subword predictions or taking `B` labels before `I` labels etc.\n",
    "\n",
    "[1]: https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\n",
    "[2]: https://www.kaggle.com/robikscube/student-writing-competition-twitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c116eb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:58:22.736623Z",
     "iopub.status.busy": "2021-12-24T18:58:22.734676Z",
     "iopub.status.idle": "2021-12-24T18:58:22.737334Z",
     "shell.execute_reply": "2021-12-24T18:58:22.737985Z",
     "shell.execute_reply.started": "2021-12-24T18:51:26.626869Z"
    },
    "papermill": {
     "duration": 0.183064,
     "end_time": "2021-12-24T18:58:22.738149",
     "exception": false,
     "start_time": "2021-12-24T18:58:22.555085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(batch):\n",
    "                \n",
    "    # MOVE BATCH TO GPU AND INFER\n",
    "    ids = batch[\"input_ids\"].to(config['device'])\n",
    "    mask = batch[\"attention_mask\"].to(config['device'])\n",
    "    outputs = model(ids, attention_mask=mask, return_dict=False)\n",
    "    all_preds = torch.argmax(outputs[0], axis=-1).cpu().numpy() \n",
    "\n",
    "    # INTERATE THROUGH EACH TEXT AND GET PRED\n",
    "    predictions = []\n",
    "    for k,text_preds in enumerate(all_preds):\n",
    "        token_preds = [ids_to_labels[i] for i in text_preds]\n",
    "\n",
    "        prediction = []\n",
    "        word_ids = batch['wids'][k].numpy()  \n",
    "        previous_word_idx = -1\n",
    "        for idx,word_idx in enumerate(word_ids):                            \n",
    "            if word_idx == -1:\n",
    "                pass\n",
    "            elif word_idx != previous_word_idx:              \n",
    "                prediction.append(token_preds[idx])\n",
    "                previous_word_idx = word_idx\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b6a278b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:58:23.114279Z",
     "iopub.status.busy": "2021-12-24T18:58:23.112633Z",
     "iopub.status.idle": "2021-12-24T18:58:23.114884Z",
     "shell.execute_reply": "2021-12-24T18:58:23.115326Z",
     "shell.execute_reply.started": "2021-12-24T18:51:26.636546Z"
    },
    "papermill": {
     "duration": 0.18449,
     "end_time": "2021-12-24T18:58:23.115470",
     "exception": false,
     "start_time": "2021-12-24T18:58:22.930980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/zzy990106/pytorch-ner-infer\n",
    "# code has been modified from original\n",
    "def get_predictions(df=test_dataset, loader=testing_loader):\n",
    "    \n",
    "    # put model in training mode\n",
    "    model.eval()\n",
    "    \n",
    "    # GET WORD LABEL PREDICTIONS\n",
    "    y_pred2 = []\n",
    "    for batch in loader:\n",
    "        labels = inference(batch)\n",
    "        y_pred2.extend(labels)\n",
    "\n",
    "    final_preds2 = []\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        idx = df.id.values[i]\n",
    "        #pred = [x.replace('B-','').replace('I-','') for x in y_pred2[i]]\n",
    "        pred = y_pred2[i] # Leave \"B\" and \"I\"\n",
    "        preds = []\n",
    "        j = 0\n",
    "        while j < len(pred):\n",
    "            cls = pred[j]\n",
    "            if cls == 'O': j += 1\n",
    "            else: cls = cls.replace('B','I') # spans start with B\n",
    "            end = j + 1\n",
    "            while end < len(pred) and pred[end] == cls:\n",
    "                end += 1\n",
    "            \n",
    "            if cls != 'O' and cls != '' and end - j > 7:\n",
    "                final_preds2.append((idx, cls.replace('I-',''),\n",
    "                                     ' '.join(map(str, list(range(j, end))))))\n",
    "        \n",
    "            j = end\n",
    "        \n",
    "    oof = pd.DataFrame(final_preds2)\n",
    "    oof.columns = ['id','class','predictionstring']\n",
    "\n",
    "    return oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f20db63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:58:23.587187Z",
     "iopub.status.busy": "2021-12-24T18:58:23.585698Z",
     "iopub.status.idle": "2021-12-24T18:58:23.601276Z",
     "shell.execute_reply": "2021-12-24T18:58:23.602082Z",
     "shell.execute_reply.started": "2021-12-24T18:51:26.649639Z"
    },
    "papermill": {
     "duration": 0.318739,
     "end_time": "2021-12-24T18:58:23.602271",
     "exception": false,
     "start_time": "2021-12-24T18:58:23.283532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from Rob Mulla @robikscube\n",
    "# https://www.kaggle.com/robikscube/student-writing-competition-twitch\n",
    "def calc_overlap(row):\n",
    "    \"\"\"\n",
    "    Calculates the overlap between prediction and\n",
    "    ground truth and overlap percentages used for determining\n",
    "    true positives.\n",
    "    \"\"\"\n",
    "    set_pred = set(row.predictionstring_pred.split(' '))\n",
    "    set_gt = set(row.predictionstring_gt.split(' '))\n",
    "    # Length of each and intersection\n",
    "    len_gt = len(set_gt)\n",
    "    len_pred = len(set_pred)\n",
    "    inter = len(set_gt.intersection(set_pred))\n",
    "    overlap_1 = inter / len_gt\n",
    "    overlap_2 = inter/ len_pred\n",
    "    return [overlap_1, overlap_2]\n",
    "\n",
    "\n",
    "def score_feedback_comp(pred_df, gt_df):\n",
    "    \"\"\"\n",
    "    A function that scores for the kaggle\n",
    "        Student Writing Competition\n",
    "        \n",
    "    Uses the steps in the evaluation page here:\n",
    "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "    \"\"\"\n",
    "    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n",
    "        .reset_index(drop=True).copy()\n",
    "    pred_df = pred_df[['id','class','predictionstring']] \\\n",
    "        .reset_index(drop=True).copy()\n",
    "    pred_df['pred_id'] = pred_df.index\n",
    "    gt_df['gt_id'] = gt_df.index\n",
    "    # Step 1. all ground truths and predictions for a given class are compared.\n",
    "    joined = pred_df.merge(gt_df,\n",
    "                           left_on=['id','class'],\n",
    "                           right_on=['id','discourse_type'],\n",
    "                           how='outer',\n",
    "                           suffixes=('_pred','_gt')\n",
    "                          )\n",
    "    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n",
    "    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n",
    "\n",
    "    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n",
    "\n",
    "    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n",
    "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "    # the prediction is a match and considered a true positive.\n",
    "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n",
    "    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n",
    "\n",
    "\n",
    "    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n",
    "    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n",
    "    tp_pred_ids = joined.query('potential_TP') \\\n",
    "        .sort_values('max_overlap', ascending=False) \\\n",
    "        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n",
    "\n",
    "    # 3. Any unmatched ground truths are false negatives\n",
    "    # and any unmatched predictions are false positives.\n",
    "    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n",
    "\n",
    "    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n",
    "    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n",
    "\n",
    "    # Get numbers of each type\n",
    "    TP = len(tp_pred_ids)\n",
    "    FP = len(fp_pred_ids)\n",
    "    FN = len(unmatched_gt_ids)\n",
    "    #calc microf1\n",
    "    my_f1_score = TP / (TP + 0.5*(FP+FN))\n",
    "    return my_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85b7ba21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T18:58:24.094780Z",
     "iopub.status.busy": "2021-12-24T18:58:24.094142Z",
     "iopub.status.idle": "2021-12-24T19:00:08.079320Z",
     "shell.execute_reply": "2021-12-24T19:00:08.079689Z",
     "shell.execute_reply.started": "2021-12-24T18:51:26.666902Z"
    },
    "papermill": {
     "duration": 104.195246,
     "end_time": "2021-12-24T19:00:08.079871",
     "exception": false,
     "start_time": "2021-12-24T18:58:23.884625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evidence 0.6434053003172004\n",
      "Concluding Statement 0.7792562265438417\n",
      "Lead 0.7491995731056563\n",
      "Position 0.6193724420190996\n",
      "Claim 0.4979180363795748\n",
      "Rebuttal 0.37546933667083854\n",
      "Counterclaim 0.48250460405156537\n",
      "\n",
      "Overall 0.5924465027268252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if COMPUTE_VAL_SCORE: # note this doesn't run during submit\n",
    "    # VALID TARGETS\n",
    "    valid = train_df.loc[train_df['id'].isin(IDS[valid_idx])]\n",
    "\n",
    "    # OOF PREDICTIONS\n",
    "    oof = get_predictions(test_dataset, testing_loader)\n",
    "\n",
    "    # COMPUTE F1 SCORE\n",
    "    f1s = []\n",
    "    CLASSES = oof['class'].unique()\n",
    "    print()\n",
    "    for c in CLASSES:\n",
    "        pred_df = oof.loc[oof['class']==c].copy()\n",
    "        gt_df = valid.loc[valid['discourse_type']==c].copy()\n",
    "        f1 = score_feedback_comp(pred_df, gt_df)\n",
    "        print(c,f1)\n",
    "        f1s.append(f1)\n",
    "    print()\n",
    "    print('Overall',np.mean(f1s))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6233e1e9",
   "metadata": {},
   "source": [
    "## old notebook results\n",
    "Position 0.6581167735403307\n",
    "Evidence 0.6565834455609655\n",
    "Concluding Statement 0.7885871433482297\n",
    "Lead 0.7886136004217185\n",
    "Claim 0.5144100054377378\n",
    "Counterclaim 0.4934823091247672\n",
    "Rebuttal 0.40609137055837563\n",
    "\n",
    "Overall 0.6151263782845893"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2613e1",
   "metadata": {
    "papermill": {
     "duration": 0.167874,
     "end_time": "2021-12-24T19:00:08.424099",
     "exception": false,
     "start_time": "2021-12-24T19:00:08.256225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Infer Test Data and Write Submission CSV\n",
    "We will now infer the test data and write submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9209ca97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:00:08.767021Z",
     "iopub.status.busy": "2021-12-24T19:00:08.766379Z",
     "iopub.status.idle": "2021-12-24T19:00:09.351444Z",
     "shell.execute_reply": "2021-12-24T19:00:09.350632Z",
     "shell.execute_reply.started": "2021-12-24T18:53:12.480399Z"
    },
    "papermill": {
     "duration": 0.759469,
     "end_time": "2021-12-24T19:00:09.351580",
     "exception": false,
     "start_time": "2021-12-24T19:00:08.592111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Lead</td>\n",
       "      <td>4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Position</td>\n",
       "      <td>41 42 43 44 45 46 47 48 49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Claim</td>\n",
       "      <td>57 58 59 60 61 62 63 64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Claim</td>\n",
       "      <td>66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>120 121 122 123 124 125 126 127 128 129 130 13...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id     class                                   predictionstring\n",
       "0  0FB0700DAF44      Lead  4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 2...\n",
       "1  0FB0700DAF44  Position                         41 42 43 44 45 46 47 48 49\n",
       "2  0FB0700DAF44     Claim                            57 58 59 60 61 62 63 64\n",
       "3  0FB0700DAF44     Claim  66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 8...\n",
       "4  0FB0700DAF44  Evidence  120 121 122 123 124 125 126 127 128 129 130 13..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = get_predictions(test_texts, test_texts_loader)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "200b03b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:00:09.702891Z",
     "iopub.status.busy": "2021-12-24T19:00:09.701913Z",
     "iopub.status.idle": "2021-12-24T19:00:09.707583Z",
     "shell.execute_reply": "2021-12-24T19:00:09.707144Z",
     "shell.execute_reply.started": "2021-12-24T18:53:13.076280Z"
    },
    "papermill": {
     "duration": 0.180565,
     "end_time": "2021-12-24T19:00:09.707700",
     "exception": false,
     "start_time": "2021-12-24T19:00:09.527135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6803ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp] *",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 228.514779,
   "end_time": "2021-12-24T19:00:12.608880",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-24T18:56:24.094101",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
